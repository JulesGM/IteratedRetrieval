{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d837c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 01:50:05,944 [INFO] faiss.loader: Loading faiss with AVX2 support.\n",
      "2021-09-09 01:50:05,946 [INFO] faiss.loader: Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2021-09-09 01:50:05,947 [INFO] faiss.loader: Loading faiss.\n",
      "2021-09-09 01:50:06,140 [INFO] faiss.loader: Successfully loaded faiss.\n",
      "[140641508927296] 2021-09-09 01:50:10,170 [INFO] common_retriever: Checking versions...\n",
      "[140641508927296] 2021-09-09 01:50:10,247 [INFO] transformers.file_utils: PyTorch version 1.7.0 available.\n",
      "[140641508927296] 2021-09-09 01:50:13,702 [INFO] common_retriever: All version checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Third party\n",
    "import hydra\n",
    "import rich\n",
    "\n",
    "# First Party\n",
    "BASE_PATH = Path(\"/home/mila/g/gagnonju/DPR/\")\n",
    "CONF_PATH = BASE_PATH/\"conf\"\n",
    "\n",
    "os.chdir(BASE_PATH)\n",
    "import dense_retriever\n",
    "import jules_validate_dense_retriever\n",
    "from dense_retriever import *\n",
    "import common_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d991cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Resets the passage cache, which is the longest load time of the \n",
    "# script at 7 min\n",
    "###########################################################################\n",
    "all_passages = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919bdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = None\n",
    "retriever = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ceea68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/.anaconda3/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'dense_retriever': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/mila/g/gagnonju/.anaconda3/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'ctx_sources/default_sources': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/mila/g/gagnonju/.anaconda3/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/retriever_default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/mila/g/gagnonju/.anaconda3/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'encoder/hf_bert': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Passed validation.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPassed validation.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ctx_datatsets'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'dpr_wiki'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ctx_sources'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'dpr_wiki'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvCtxSrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'data.wikipedia_split.psgs_w100'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'id_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'datasets'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'nq_test'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.nq-test'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'nq_train'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.nq-train'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'nq_dev'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.nq-dev'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trivia_test'</span>: \n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.trivia-test'</span><span style=\"font-weight: bold\">}</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trivia_train'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.trivia-train'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'trivia_dev'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.trivia-dev'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'webq_test'</span>: \n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.webq-test'</span><span style=\"font-weight: bold\">}</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'curatedtrec_test'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.data.retriever_data.CsvQASrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'data.retriever.qas.curatedtrec-test'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'device'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'distributed_world_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'do_lower_case'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'encoded_ctx_files'</span>: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'/home/mila/g/gagnonju/DPR/downloads/data/wikipedia_split/psgs_w100.tsv'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'encoder'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'encoder_model_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'hf_bert'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained_model_cfg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bert-base-uncased'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'pretrained_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'projection_dim'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sequence_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dropout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'fix_ctx_encoder'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'encoder_path'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fp16'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fp16_opt_level'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'O1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'global_loss_buf_sz'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'index_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/mila/g/gagnonju/DPR/dpr/downloads/indexes/single/nq/full'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'indexer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flat'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'indexers'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'flat'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.indexer.faiss_indexers.DenseFlatIndexer'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hnsw'</span>:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dpr.indexer.faiss_indexers.DenseHNSWFlatIndexer'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hnsw_sq'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'dpr.indexer.faiss_indexers.DenseHNSWSQIndexer'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'kilt_out_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'local_rank'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'match'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'string'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/mila/g/gagnonju/DPR/dpr/downloads/checkpoint/retriever/single/nq/ber</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">t-base-encoder.cp'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_docs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_gpu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'no_cuda'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'out_file'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'qa_dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'nq_test'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'rpc_retriever_cfg_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'special_tokens'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'validate_as_tables'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'validation_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
       "    \u001b[32m'ctx_datatsets'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'dpr_wiki'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'ctx_sources'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dpr_wiki'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvCtxSrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \n",
       "\u001b[32m'data.wikipedia_split.psgs_w100'\u001b[0m, \u001b[32m'id_prefix'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'datasets'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'nq_test'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \n",
       "\u001b[32m'data.retriever.qas.nq-test'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'nq_train'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \n",
       "\u001b[32m'file'\u001b[0m: \u001b[32m'data.retriever.qas.nq-train'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'nq_dev'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[32m'data.retriever.qas.nq-dev'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'trivia_test'\u001b[0m: \n",
       "\u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[32m'data.retriever.qas.trivia-test'\u001b[0m\u001b[1m}\u001b[0m, \n",
       "\u001b[32m'trivia_train'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \n",
       "\u001b[32m'data.retriever.qas.trivia-train'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'trivia_dev'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[32m'data.retriever.qas.trivia-dev'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'webq_test'\u001b[0m: \n",
       "\u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \u001b[32m'data.retriever.qas.webq-test'\u001b[0m\u001b[1m}\u001b[0m, \n",
       "\u001b[32m'curatedtrec_test'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.data.retriever_data.CsvQASrc'\u001b[0m, \u001b[32m'file'\u001b[0m: \n",
       "\u001b[32m'data.retriever.qas.curatedtrec-test'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'device'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'distributed_world_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'do_lower_case'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'encoded_ctx_files'\u001b[0m: \n",
       "\u001b[1m[\u001b[0m\u001b[32m'/home/mila/g/gagnonju/DPR/downloads/data/wikipedia_split/psgs_w100.tsv'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'encoder'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'encoder_model_type'\u001b[0m: \u001b[32m'hf_bert'\u001b[0m, \u001b[32m'pretrained_model_cfg'\u001b[0m: \u001b[32m'bert-base-uncased'\u001b[0m,\n",
       "\u001b[32m'pretrained_file'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'projection_dim'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'sequence_length'\u001b[0m: \u001b[1;36m256\u001b[0m, \u001b[32m'dropout'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \n",
       "\u001b[32m'fix_ctx_encoder'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'encoder_path'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'fp16'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'fp16_opt_level'\u001b[0m: \u001b[32m'O1'\u001b[0m,\n",
       "    \u001b[32m'global_loss_buf_sz'\u001b[0m: \u001b[1;36m150000\u001b[0m,\n",
       "    \u001b[32m'index_path'\u001b[0m: \u001b[32m'/home/mila/g/gagnonju/DPR/dpr/downloads/indexes/single/nq/full'\u001b[0m,\n",
       "    \u001b[32m'indexer'\u001b[0m: \u001b[32m'flat'\u001b[0m,\n",
       "    \u001b[32m'indexers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'flat'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.indexer.faiss_indexers.DenseFlatIndexer'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'hnsw'\u001b[0m:\n",
       "\u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \u001b[32m'dpr.indexer.faiss_indexers.DenseHNSWFlatIndexer'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'hnsw_sq'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'dpr.indexer.faiss_indexers.DenseHNSWSQIndexer'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'kilt_out_file'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'local_rank'\u001b[0m: \u001b[1;36m-1\u001b[0m,\n",
       "    \u001b[32m'match'\u001b[0m: \u001b[32m'string'\u001b[0m,\n",
       "    \u001b[32m'model_file'\u001b[0m: \u001b[32m'/home/mila/g/gagnonju/DPR/dpr/downloads/checkpoint/retriever/single/nq/ber\u001b[0m\n",
       "\u001b[32mt-base-encoder.cp'\u001b[0m,\n",
       "    \u001b[32m'n_docs'\u001b[0m: \u001b[1;36m100\u001b[0m,\n",
       "    \u001b[32m'n_gpu'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'no_cuda'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'out_file'\u001b[0m: \u001b[32m'/home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py'\u001b[0m,\n",
       "    \u001b[32m'qa_dataset'\u001b[0m: \u001b[32m'nq_test'\u001b[0m,\n",
       "    \u001b[32m'rpc_retriever_cfg_file'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'special_tokens'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'validate_as_tables'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'validation_workers'\u001b[0m: \u001b[1;36m15\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-09 01:50:14,403][root][INFO] - args.local_rank -1\n",
      "[2021-09-09 01:50:14,405][root][INFO] - WORLD_SIZE None\n",
      "[2021-09-09 01:50:14,480][root][INFO] - Initialized host cn-c004 as d.rank -1 on device=cuda, n_gpu=1, world size=1\n",
      "[2021-09-09 01:50:14,481][root][INFO] - 16-bits training: False \n",
      "[2021-09-09 01:50:14,483][root][INFO] - CFG (after gpu  configuration):\n",
      "[2021-09-09 01:50:14,493][root][INFO] - encoder:\n",
      "  encoder_model_type: hf_bert\n",
      "  pretrained_model_cfg: bert-base-uncased\n",
      "  pretrained_file: null\n",
      "  projection_dim: 0\n",
      "  sequence_length: 256\n",
      "  dropout: 0.1\n",
      "  fix_ctx_encoder: false\n",
      "  pretrained: true\n",
      "datasets:\n",
      "  nq_test:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.nq-test\n",
      "  nq_train:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.nq-train\n",
      "  nq_dev:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.nq-dev\n",
      "  trivia_test:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.trivia-test\n",
      "  trivia_train:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.trivia-train\n",
      "  trivia_dev:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.trivia-dev\n",
      "  webq_test:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.webq-test\n",
      "  curatedtrec_test:\n",
      "    _target_: dpr.data.retriever_data.CsvQASrc\n",
      "    file: data.retriever.qas.curatedtrec-test\n",
      "ctx_sources:\n",
      "  dpr_wiki:\n",
      "    _target_: dpr.data.retriever_data.CsvCtxSrc\n",
      "    file: data.wikipedia_split.psgs_w100\n",
      "    id_prefix: ''\n",
      "indexers:\n",
      "  flat:\n",
      "    _target_: dpr.indexer.faiss_indexers.DenseFlatIndexer\n",
      "  hnsw:\n",
      "    _target_: dpr.indexer.faiss_indexers.DenseHNSWFlatIndexer\n",
      "  hnsw_sq:\n",
      "    _target_: dpr.indexer.faiss_indexers.DenseHNSWSQIndexer\n",
      "out_file: /home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py\n",
      "validation_workers: 15\n",
      "n_gpu: 1\n",
      "qa_dataset: nq_test\n",
      "ctx_datatsets:\n",
      "- dpr_wiki\n",
      "encoded_ctx_files:\n",
      "- /home/mila/g/gagnonju/DPR/downloads/data/wikipedia_split/psgs_w100.tsv\n",
      "match: string\n",
      "n_docs: 100\n",
      "batch_size: 128\n",
      "do_lower_case: true\n",
      "encoder_path: null\n",
      "index_path: /home/mila/g/gagnonju/DPR/dpr/downloads/indexes/single/nq/full\n",
      "kilt_out_file: null\n",
      "model_file: /home/mila/g/gagnonju/DPR/dpr/downloads/checkpoint/retriever/single/nq/bert-base-encoder.cp\n",
      "validate_as_tables: false\n",
      "rpc_retriever_cfg_file: null\n",
      "indexer: flat\n",
      "special_tokens: null\n",
      "local_rank: -1\n",
      "global_loss_buf_sz: 150000\n",
      "device: cuda\n",
      "distributed_world_size: 1\n",
      "no_cuda: false\n",
      "fp16: false\n",
      "fp16_opt_level: O1\n",
      "\n",
      "[2021-09-09 01:50:14,494][root][INFO] - qa_dataset: nq_test\n",
      "[2021-09-09 01:50:14,504][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/nq-test.qa.csv\n",
      "[2021-09-09 01:50:14,506][dpr.data.download_data][INFO] - Download root_dir /home/mila/g/gagnonju/DPR\n",
      "[2021-09-09 01:50:14,509][dpr.data.download_data][INFO] - File to be downloaded as /home/mila/g/gagnonju/DPR/downloads/data/retriever/qas/nq-test.csv\n",
      "[2021-09-09 01:50:14,511][dpr.data.download_data][INFO] - File already exist /home/mila/g/gagnonju/DPR/downloads/data/retriever/qas/nq-test.csv\n",
      "[2021-09-09 01:50:14,512][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE\n",
      "[2021-09-09 01:50:14,514][dpr.data.download_data][INFO] - File already exist /home/mila/g/gagnonju/DPR/downloads/data/retriever/qas/LICENSE\n",
      "[2021-09-09 01:50:14,515][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README\n",
      "[2021-09-09 01:50:14,517][dpr.data.download_data][INFO] - File already exist /home/mila/g/gagnonju/DPR/downloads/data/retriever/qas/README\n",
      "[2021-09-09 01:50:14,568][root][INFO] - Using custom representation token selector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['out_file=/home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py']\n",
      "An error occurred during Hydra's exception formatting:\n",
      "AssertionError()\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'retriever' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36mrun_and_report\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    251\u001b[0m                         \u001b[0mmdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                         \u001b[0;32massert\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0023b5c368c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;34m\"out_file=/home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m ]\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/main.py\u001b[0m in \u001b[0;36mdecorated_main\u001b[0;34m(cfg_passthrough)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# no return value from run_hydra() as it may sometime actually run the task_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# multiple times (--multirun)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 _run_hydra(\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0margs_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mtask_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_run_hydra\u001b[0;34m(args_parser, task_function, config_path, config_name)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             run_and_report(\n\u001b[0m\u001b[1;32m    378\u001b[0m                 lambda: hydra.run(\n\u001b[1;32m    379\u001b[0m                     \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36mrun_and_report\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinesep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 )\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36mrun_and_report\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_and_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_env_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HYDRA_FULL_ERROR\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_under_debugger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             run_and_report(\n\u001b[0;32m--> 378\u001b[0;31m                 lambda: hydra.run(\n\u001b[0m\u001b[1;32m    379\u001b[0m                     \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                     \u001b[0mtask_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/_internal/hydra.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, config_name, task_function, overrides, with_log_configuration)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# access the result to trigger an exception in case the job failed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/core/utils.py\u001b[0m in \u001b[0;36mreturn_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;34mf\"Error executing job with overrides: {self.overrides}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinesep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             )\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mreturn_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.8/site-packages/hydra/core/utils.py\u001b[0m in \u001b[0;36mrun_job\u001b[0;34m(task_function, config, job_dir_key, job_subdir_key, configure_logging, hydra_context)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_job_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJobStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0023b5c368c4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mqa_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using custom representation token selector\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id_prefixes per dataset: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'retriever' referenced before assignment"
     ]
    }
   ],
   "source": [
    "@hydra.main(config_path=CONF_PATH, config_name=\"dense_retriever\")\n",
    "def main(cfg):\n",
    "    ###########################################################################\n",
    "    # Complete and validate CFG\n",
    "    ###########################################################################\n",
    "    jules_validate_dense_retriever.validate(\n",
    "        {k: getattr(cfg, k) for k in dir(cfg)}, \n",
    "        dense_retriever.SCHEMA_PATH,\n",
    "    )\n",
    "    cfg = dense_retriever.setup_cfg_gpu(cfg)\n",
    "\n",
    "    assert cfg.out_file, cfg.out_file\n",
    "    assert Path(cfg.out_file).parent.exists(), cfg.out_file\n",
    "\n",
    "    logger.info(\"CFG (after gpu  configuration):\")\n",
    "    logger.info(\"%s\", OmegaConf.to_yaml(cfg))\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    # Prepare models\n",
    "    ###########################################################################\n",
    "#     saved_state = load_states_from_checkpoint(cfg.model_file)\n",
    "#     set_cfg_params_from_state(saved_state.encoder_params, cfg)\n",
    "\n",
    "#     tensorizer, encoder, _ = init_biencoder_components(\n",
    "#         cfg.encoder.encoder_model_type, cfg, inference_only=True\n",
    "#     )\n",
    "\n",
    "#     encoder_path = cfg.encoder_path\n",
    "#     if encoder_path:\n",
    "#         logger.info(\"Selecting encoder: %s\", encoder_path)\n",
    "#         encoder = getattr(encoder, encoder_path)\n",
    "#     else:\n",
    "#         logger.info(\"Selecting standard question encoder\")\n",
    "#         encoder = encoder.question_model\n",
    "\n",
    "#     encoder, _ = setup_for_distributed_mode(\n",
    "#         encoder, \n",
    "#         None, \n",
    "#         cfg.device, \n",
    "#         cfg.n_gpu, \n",
    "#         cfg.local_rank, \n",
    "#         cfg.fp16\n",
    "#     )\n",
    "#     encoder.eval()\n",
    "\n",
    "#     # load weights from the model file\n",
    "#     model_to_load = get_model_obj(encoder)\n",
    "#     logger.info(\"Loading saved model state ...\")\n",
    "\n",
    "#     encoder_prefix = (\n",
    "#         encoder_path if encoder_path else \"question_model\") + \".\"\n",
    "#     prefix_len = len(encoder_prefix)\n",
    "\n",
    "#     logger.info(\"Encoder state prefix %s\", encoder_prefix)\n",
    "#     question_encoder_state = {\n",
    "#         key[prefix_len:]: value\n",
    "#         for (key, value) in saved_state.model_dict.items()\n",
    "#         if key.startswith(encoder_prefix)\n",
    "#     }\n",
    "#     # TODO: long term HF state compatibility fix\n",
    "#     model_to_load.load_state_dict(question_encoder_state, strict=False)\n",
    "#     vector_size = model_to_load.get_out_size()\n",
    "#     logger.info(\"Encoder vector_size=%d\", vector_size)\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    # Prepare sources\n",
    "    ###########################################################################\n",
    "#     rich.print(\"[red bold]Starting the thing.\")\n",
    "#     id_prefixes = []\n",
    "#     ctx_sources = []\n",
    "#     for ctx_src in cfg.ctx_datatsets:\n",
    "#         ctx_src = hydra.utils.instantiate(cfg.ctx_sources[ctx_src])\n",
    "#         id_prefixes.append(ctx_src.id_prefix)\n",
    "#         ctx_sources.append(ctx_src)\n",
    "    \n",
    "#     rich.print(ctx_sources)\n",
    "#     rich.print(\"[red bold]Second part.\")\n",
    "    \n",
    "#     global all_passages\n",
    "#     if all_passages is None:\n",
    "#         all_passages = {}\n",
    "#         for ctx_src in ctx_sources:\n",
    "#             ctx_src.load_data_to(all_passages)\n",
    "#             rich.print(\"[green]Done loading passages.\")\n",
    "#         print(len(all_passages))\n",
    "\n",
    "    ###########################################################################\n",
    "    # Load Index & Prepare retriever\n",
    "    ###########################################################################\n",
    "\n",
    "#     index_path = cfg.index_path\n",
    "#     #------------\n",
    "#     ## Instantiate the index and create a retriever\n",
    "#     #------------\n",
    "#     global index\n",
    "#     global retriever\n",
    "#     if index is None or retriever is None:\n",
    "#         rich.print(f\"[bold blue]Loading index.\")\n",
    "#         index = hydra.utils.instantiate(cfg.indexers[cfg.indexer])\n",
    "#         logger.info(\"Index class %s \", type(index))\n",
    "#         index_buffer_sz = index.buffer_size\n",
    "#         index.init_index(vector_size)\n",
    "#         rich.print(f\"[bold blue]Done loading index.\")\n",
    "#         rich.print(f\"[bold blue]Loading retriever.\")\n",
    "#         retriever = LocalFaissRetriever(\n",
    "#             encoder, \n",
    "#             cfg.batch_size, \n",
    "#             tensorizer, \n",
    "#             index,\n",
    "#         )\n",
    "#         rich.print(f\"[bold blue]Loaded retriever.\")\n",
    "#         if index_path and index.index_exists(index_path):\n",
    "#             logger.info(\"Index path: %s\", index_path)\n",
    "#             retriever.index.deserialize(index_path)\n",
    "#         else:\n",
    "#             logger.info(\"Reading all passages data from files: %s\", input_paths)\n",
    "#             retriever.index_encoded_data(\n",
    "#                 input_paths, \n",
    "#                 index_buffer_sz, \n",
    "#                 path_id_prefixes=path_id_prefixes,\n",
    "#             )\n",
    "#             if index_path:\n",
    "#                 retriever.index.serialize(index_path)\n",
    "#     else:\n",
    "#         index_buffer_sz = index.buffer_size\n",
    "#         rich.print(f\"[bold green]Using cached index.\")\n",
    "#         rich.print(f\"[bold green]Using cached retriever.\")\n",
    "        \n",
    "\n",
    "    #------------\n",
    "    ## Index all passages\n",
    "    #------------\n",
    "#     ctx_files_patterns = cfg.encoded_ctx_files\n",
    "\n",
    "#     logger.info(\"ctx_files_patterns: %s\", ctx_files_patterns)\n",
    "#     if ctx_files_patterns:\n",
    "#         assert len(ctx_files_patterns) == len(\n",
    "#             id_prefixes\n",
    "#         ), \"ctx len={} pref leb={}\".format(\n",
    "#             len(ctx_files_patterns), \n",
    "#             len(id_prefixes),\n",
    "#         )\n",
    "#     else:\n",
    "#         assert (\n",
    "#             index_path\n",
    "#         ), \"Either encoded_ctx_files or index_path parameter should be set.\"\n",
    "\n",
    "#     input_paths = []\n",
    "#     path_id_prefixes = []\n",
    "#     for i, pattern in enumerate(ctx_files_patterns):\n",
    "#         pattern_files = glob.glob(pattern)\n",
    "#         pattern_id_prefix = id_prefixes[i]\n",
    "#         input_paths.extend(pattern_files)\n",
    "#         path_id_prefixes.extend([pattern_id_prefix] * len(pattern_files))\n",
    "\n",
    "#     logger.info(\"Embeddings files id prefixes: %s\", path_id_prefixes)\n",
    "    \n",
    "       \n",
    "    ###########################################################################\n",
    "    # Prepare questions and answers\n",
    "    ###########################################################################\n",
    "    questions = []\n",
    "    question_answers = []\n",
    "\n",
    "    if not cfg.qa_dataset:\n",
    "        logger.warning(\"Please specify qa_dataset to use\")\n",
    "        return\n",
    "\n",
    "    ds_key = cfg.qa_dataset\n",
    "    logger.info(\"qa_dataset: %s\", ds_key)\n",
    "\n",
    "    qa_src = hydra.utils.instantiate(cfg.datasets[ds_key])\n",
    "    qa_src.load_data()\n",
    "    assert not qa_src.selector, qa_src.selector\n",
    "    logger.info(\"Using custom representation token selector\")\n",
    "    retriever.selector = qa_src.selector\n",
    "\n",
    "    logger.info(\"id_prefixes per dataset: %s\", id_prefixes)\n",
    "\n",
    "    for ds_item in qa_src.data:\n",
    "        question, answers = ds_item.query, ds_item.answers\n",
    "        questions.append(question)\n",
    "        question_answers.append(answers)\n",
    "\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Get top k results.\n",
    "    ###########################################################################\n",
    "    logger.info(\n",
    "        \"Using special token %s\", \n",
    "        qa_src.special_query_token,\n",
    "    )\n",
    "    questions_tensor = retriever.generate_question_vectors(\n",
    "        questions, \n",
    "        query_token=qa_src.special_query_token,\n",
    "    )\n",
    "    \n",
    "    rich.print(\n",
    "        f\"[bold]get_top_docs: Starting. Approx 7 min. {timestamp()}\"\n",
    "    )\n",
    "    top_ids_and_scores = retriever.get_top_docs(\n",
    "        questions_tensor.numpy(), \n",
    "        cfg.n_docs,\n",
    "    )\n",
    "    rich.print(\"[bold green]get_top_docs: Done.\")\n",
    "\n",
    "    # we no longer need the index\n",
    "    retriever = None\n",
    "\n",
    "    if len(all_passages) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No passages data found. Please specify \"\n",
    "            \"ctx_file param properly.\"\n",
    "        )\n",
    "\n",
    "    rich.print(\"[green bold]All done.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "sys.argv = [\n",
    "    \"fake.py\", \n",
    "    \"out_file=/home/mila/g/gagnonju/DPR/outputs/integrated_script_attempt.py\",\n",
    "]\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaff0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATION_TECHNIQUES = dict()\n",
    "MAX_LOOP_N = 15\n",
    "MODEL_PATH = None\n",
    "CONCATENATION_TECHNIQUE = None\n",
    "BATCH_SIZE_QUESTIONS = 10\n",
    "OUTPUT_FILES_ROOT = None\n",
    "\n",
    "make_batches = more_itertools.ichunked\n",
    "\n",
    "\n",
    "def write_contexts(\n",
    "    all_contexts, \n",
    "    context_ids, \n",
    "    output_files_root, \n",
    "    loop_i,\n",
    "):\n",
    "    with open(\n",
    "        output_files_root/f\"contexts_{loop_i}.txt\", \n",
    "        \"a\",\n",
    "    ) as f_out:\n",
    "        for context_id in context_ids:\n",
    "            f_out.write(all_contexts[context_id].strip() + \"\\n\")\n",
    "\n",
    "def write_generations(\n",
    "    generated_text,\n",
    "    output_files_root, \n",
    "    loop_i,\n",
    "):\n",
    "    with open(\n",
    "        output_files_root/f\"generated_{loop_i}.txt\", \n",
    "        \"a\",\n",
    "    ) as f_out:\n",
    "        text = \"\\n\".join((x.strip() for x in generated_text))\n",
    "        f_out.write(text)\n",
    "\n",
    "def inference(\n",
    "    all_contexts,\n",
    "    max_loop_n=MAX_LOOP_N, \n",
    "    model_path=MODEL_PATH, \n",
    "    concatenation_technique=CONCATENATION_TECHNIQUE,\n",
    "    output_files_root=OUTPUT_FILES_ROOT,\n",
    "):\n",
    "    \"\"\"\n",
    "    We currently do \n",
    "    \n",
    "    for batch_questions in questions:\n",
    "        for loop_i in range(max_loop_n)\n",
    "            encode_context_to_gen\n",
    "            (load generator to faster memory)\n",
    "            generate(batch)\n",
    "            decode_text_from_gen\n",
    "            \n",
    "            encode_text_to_retriever\n",
    "            (load retriever to faster memory)\n",
    "            retrieve(batch)\n",
    "            decode_text_from_retriever\n",
    "    \n",
    "    We could do\n",
    "    \n",
    "    for loop_i in range(max_loop_n)\n",
    "        # Parallelize as needed if helpful\n",
    "        # num_questions x num_beams to do\n",
    "        for batch_questions in zip(\n",
    "            retrieved_contexts\n",
    "        ):\n",
    "            encode_contexts_to_gen\n",
    "        \n",
    "        (imaginary barrier)\n",
    "        (load generator to faster memory)    \n",
    "        for batch_questions in questions:\n",
    "            top_beam_ids, top_beam_ppls = generate(batch)\n",
    "            \n",
    "        # Parallelize as needed if helpful\n",
    "        for batch_questions in questions:\n",
    "            decode_text_from_gen\n",
    "            \n",
    "        # Parallelize as needed if helpful\n",
    "        for batch_questions in questions:\n",
    "            encode_text_to_retriever\n",
    "\n",
    "        (imaginary barrier)\n",
    "        # Parallelize as needed if helpful\n",
    "        for batch_questions in questions:\n",
    "            concatenate_contexts\n",
    "\n",
    "        (imaginary barrier)\n",
    "        (load retriever to faster memory)\n",
    "        for batch_questions in questions:            \n",
    "            retrieve(batch)\n",
    "        \n",
    "        # Parallelize as needed if helpful\n",
    "        for batch_questions in questions:            \n",
    "            decode_text_from_retriever\n",
    "    \n",
    "    Much better for GPU memory locality,\n",
    "    worse for total memory use. Would maybe allow\n",
    "    for slightly larger batches.\n",
    "    \n",
    "    I think that the fact that we don't need the \n",
    "    GPU results right away makes it async and faster\n",
    "    \n",
    "    \"\"\"\n",
    "    output_files_root = pathlib.Path(output_files_root)\n",
    "    model = load_model(model_path)\n",
    "    concatenation_technique = CONCATENATION_TECHNIQUES[\n",
    "        concatenation_technique\n",
    "    ]\n",
    "    question_batches = make_batches(questions)\n",
    "    \n",
    "    context_ids_accum = [[] for _ in range(max_loop_n)]\n",
    "    generation_text_accum = [[] for _ in range(max_loop_n)]\n",
    "    \n",
    "    for question_batch in question_batches:\n",
    "        retrieval_query = question\n",
    "        all_generations = []\n",
    "        contexts = retrieve(retrieval_query)\n",
    "\n",
    "        for loop_i in range(max_loop_n):\n",
    "            top_beams_ids, top_beams_ppl = generate(\n",
    "                question, contexts,\n",
    "            )\n",
    "            \n",
    "            # Detokenize top_beams_ids.\n",
    "            # We do this here because we don't have the choice?\n",
    "            # Maybe we do though.\n",
    "            # batch_size x num_beams x (variable num_words)\n",
    "            top_beams_text = []\n",
    "            for unit in top_beams_ids:\n",
    "                top_beams_text.append([\n",
    "                    tokenizer_generator.decode(ids_beam) \n",
    "                    for ids_beam in unit\n",
    "                ])\n",
    "            \n",
    "            # We likely have to decode and re-encode here\n",
    "            retrieval_query = concatenation_technique(\n",
    "                question, \n",
    "                top_beams_text,\n",
    "                top_beams_ppl,\n",
    "                all_results, \n",
    "                loop_i,\n",
    "            )\n",
    "            \n",
    "            context_ids = retrieve(retrieval_query)            \n",
    "            generation_text_accum[loop_i].append(top_beams_text)\n",
    "            context_ids_accum[loop_i].append(contexts)\n",
    "    \n",
    "    \n",
    "    # The following are bad, \n",
    "    context_text_accum = [[] for _ in range(max_loop_n)]\n",
    "\n",
    "    \n",
    "    for i, batch in enumerate(context_ids_accum):\n",
    "        for id_ in batch:\n",
    "            context_text_accum[i].append(all_contexts[id_])\n",
    "    \n",
    "    # [Validate somewhere]\n",
    "    \n",
    "#             write_contexts(\n",
    "#                 all_contexts, \n",
    "#                 context_ids, \n",
    "#                 output_files_root, \n",
    "#                 loop_i,\n",
    "#             )\n",
    "            \n",
    "#             write_generations(\n",
    "#                 generated_text,\n",
    "#                 output_files_root,\n",
    "#                 loop_i,\n",
    "#             )\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
