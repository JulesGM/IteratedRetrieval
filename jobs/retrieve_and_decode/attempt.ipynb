{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be40be64-ea72-4329-99ea-790e5b9ef74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29159c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">data_dir = PosixPath(</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'/home/mila/g/gagnonju/IteratedDecoding/GAR/data/nq-answer'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mdata_dir = \u001b[0m\u001b[1;31mPosixPath\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m'/home/mila/g/gagnonju/IteratedDecoding/GAR/data/nq-answer'\u001b[0m\u001b[1;31m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from /home/mila/g/gagnonju/IteratedDecoding/GAR/data/nq-answer/val.target.processed (pkl)... make sure data is what you need\n"
     ]
    }
   ],
   "source": [
    "CONFIG_RAN_ALL_THE_WAY = False\n",
    "\n",
    "###############################################################################\n",
    "# Imports\n",
    "###############################################################################\n",
    "# Standard library\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from typing import *\n",
    "\n",
    "# Third party\n",
    "import colorama\n",
    "import transformers\n",
    "assert int(transformers.__version__.split('.')[0]) >= 4, transformers.__version__\n",
    "\n",
    "# First Party\n",
    "import iterated_utils as utils\n",
    "import iterated_retrieval as ir\n",
    "import iterated_retrieval\n",
    "import common_retriever\n",
    "\n",
    "\n",
    "ROOT_PATH = Path(\"/home/mila/g/gagnonju/IteratedDecoding/\")\n",
    "\n",
    "assert \"condaless\" in sys.executable, sys.executable\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Logging\n",
    "###############################################################################\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "format_info = (\n",
    "    \"[%(levelname)s] (%(asctime)s) \"\n",
    "    \"{%(name)s.%(funcName)s:%(lineno)d}:\\n\"\n",
    ")\n",
    "\n",
    "logging_format = (\n",
    "    colorama.Fore.CYAN +\n",
    "    format_info +\n",
    "    colorama.Style.RESET_ALL +\n",
    "    \"%(message)s\"\n",
    ")\n",
    "logging.basicConfig(\n",
    "    format=logging_format,\n",
    "    level=logging.WARNING,\n",
    "    force=True,\n",
    ")\n",
    "logging.getLogger(\n",
    "    \"transformers.configuration_utils\"\n",
    ").setLevel(logging.WARN)\n",
    "logging.getLogger(\n",
    "    \"transformers.tokenization_utils\"\n",
    ").setLevel(logging.WARN)\n",
    "logging.getLogger(\n",
    "    \"transformers.modeling_utils\"\n",
    ").setLevel(logging.WARN)\n",
    "logging.getLogger(\n",
    "    \"common_retriever\"\n",
    ").setLevel(logging.INFO)\n",
    "logging.getLogger(\n",
    "    \"dense_retriever\"\n",
    ").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG\n",
    "###############################################################################\n",
    "conf_path = ROOT_PATH / \"jobs\" / \"retrieve_and_decode\" / \"config.json\"\n",
    "args, dpr_cfg = ir.build_args(config_path=conf_path, root_path=ROOT_PATH)\n",
    "\n",
    "(\n",
    "    dataloader, tokenizer_bart, tokenizer_bert,\n",
    ") = iterated_retrieval.build_tokenizers_and_datasets(\n",
    "    generation_batch_size=args.generation_batch_size,\n",
    "    data_dir=args.data_dir,\n",
    "    max_target_len=args.dataloader_max_target_len,\n",
    "    max_source_len=args.dataloader_max_source_len,\n",
    "    cv_set=args.cv_set\n",
    ")\n",
    "\n",
    "\n",
    "LOGGER.info(\"Done.\")\n",
    "CONFIG_RAN_ALL_THE_WAY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9afb759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[INFO] (2021-11-15 10:16:44,852) {common_retriever.make_retriever:217}:\n",
      "\u001b[0mLoading encoders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re)/Loading hf_models.py\n",
      "hf_models.py: Third Party\n",
      "4.12.0\n",
      "hf_models.py: First Party\n",
      "hf_models.py:  Code\n",
      "hf_model.py: Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing HFBertEncoder: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing HFBertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HFBertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing HFBertEncoder: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing HFBertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HFBertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[36m[INFO] (2021-11-15 10:17:05,014) {common_retriever.make_retriever:323}:\n",
      "\u001b[0mretriever.index.deserialize /home/mila/g/gagnonju/IteratedDecoding/DPR/dpr/downloads/indexes/single/nq/full, takes 11 min\n",
      "\u001b[36m[INFO] (2021-11-15 10:18:36,864) {common_retriever.make_retriever:339}:\n",
      "\u001b[0mEmb. files id prefixes: ['']\n",
      "\u001b[36m[INFO] (2021-11-15 10:18:37,403) {common_retriever.load_data:139}:\n",
      "\u001b[0mqa_dataset: nq_test\n",
      "\u001b[36m[INFO] (2021-11-15 10:18:37,404) {common_retriever.load_data:141}:\n",
      "\u001b[0mload_data: hydra.utils.instantiate(cfg.datasets[ds_key])\n",
      "\u001b[36m[INFO] (2021-11-15 10:18:37,960) {common_retriever.load_data:147}:\n",
      "\u001b[0mUsing custom representation token selector\n",
      "\u001b[36m[INFO] (2021-11-15 10:18:37,962) {common_retriever.faiss_to_gpu:457}:\n",
      "\u001b[0m4 GPUs\n"
     ]
    }
   ],
   "source": [
    "retriever, all_passages, special_query_token = common_retriever.build_retriever(\n",
    "    dpr_cfg,\n",
    "    ROOT_PATH / \"jobs\" / \"retrieve_and_decode\" / \"cache\" \n",
    ")\n",
    "retriever.index.index = common_retriever.faiss_to_gpu(\n",
    "    retriever.index.index,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cbde20-f004-48cc-af20-40efbc61801e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_aug_model, reader_model = ir.build_models(\n",
    "    reader_model_path=args.reader_model_path,\n",
    "    query_aug_model_path=args.query_aug_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59095362-39ea-45dd-bc2b-bbef7f087e61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Re)/Loading iterated_retrieval.py\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_return_sequences'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_beams'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_beam_groups'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'early_stopping'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'do_sample'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'num_return_sequences'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "    \u001b[32m'max_length'\u001b[0m: \u001b[1;36m40\u001b[0m,\n",
       "    \u001b[32m'num_beams'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'num_beam_groups'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'temperature'\u001b[0m: \u001b[1;36m5.0\u001b[0m,\n",
       "    \u001b[32m'early_stopping'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'do_sample'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[loop_i = 0] Preparing the retrieval queries ::  question_generator: 100%|██████████| 1752/1752 [00:00<00:00, 4028.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/IteratedDecoding/jobs/retrieve_and_decode/iterated_decoding_output/y2021m11d15-h10m21s57_ANSWER_CONCATENATE_ARGMAX_W_AUG_100_FINAL_NUM_CONTEXTS_100_TEMPERATURE_5.0/retr_inputs_0.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieval all_queries_this_loop:  57%|█████▋    | 5020/8757 [03:22<02:29, 24.92it/s]"
     ]
    }
   ],
   "source": [
    "assert CONFIG_RAN_ALL_THE_WAY\n",
    "\n",
    "ir.inference(\n",
    "    all_passages=all_passages,\n",
    "    query_aug_model=query_aug_model.cuda(),\n",
    "    reader_model=reader_model.cuda() if reader_model else None,\n",
    "    special_query_token=special_query_token,\n",
    "    retriever=retriever,\n",
    "    selection_technique=ir.selection_technique,\n",
    "    question_dataloader=dataloader,\n",
    "    max_loop_n=args.max_loop_n,\n",
    "    query_aug_input_max_length=args.max_source_len,\n",
    "    decoding_conf_query_aug=args.decoding_conf_query_aug,\n",
    "    decoding_conf_reader=args.decoding_conf_reader,\n",
    "    n_docs=args.n_docs,\n",
    "    out_path=args.out_path,\n",
    "    retriever_batch_size=args.retriever_batch_size,\n",
    "    aug_method=args.aug_method,\n",
    "    final_num_contexts=args.final_num_contexts,\n",
    "    generation_batch_size=args.generation_batch_size,\n",
    "    selection_mode=args.selection_mode,\n",
    "    tokenizer_bart=tokenizer_bart,\n",
    "    tokenizer_bert=tokenizer_bert,\n",
    "    augmentation_mode=args.augmentation_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b9bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b3376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb46d76ee84c521c9729e5bfd8a0e0e1022274a04a4ed834d9ed473069ce4070"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('condaless': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
