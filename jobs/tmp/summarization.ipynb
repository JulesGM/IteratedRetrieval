{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rich\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "DIR_PATH = Path(\"/home/mila/g/gagnonju/IteratedDecoding/jobs/tmp/\")\n",
    "\n",
    "pegasus_names = [\n",
    "    \"google/pegasus-pubmed\", \n",
    "    \"google/pegasus-arxiv\",\n",
    "]\n",
    "\n",
    "bigbird_names = [\n",
    "    \"google/bigbird-pegasus-large-pubmed\",\n",
    "    \"google/bigbird-pegasus-large-arxiv\",\n",
    "]\n",
    "\n",
    "active_model_name = \"google/bigbird-pegasus-large-pubmed\"\n",
    "\n",
    "# By default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(active_model_name)\n",
    "\n",
    "model = transformers.BigBirdPegasusForConditionalGeneration.from_pretrained(active_model_name)\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6311 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# https://pubmed.ncbi.nlm.nih.gov/30426489/\n",
    "text = (DIR_PATH / \"advances_breast_cancer.txt\").read_text().replace(\"## \", \"\")\n",
    "tmp = tokenizer(text, return_tensors='pt')\n",
    "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "if torch.cuda.is_available():\n",
    "    inputs.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/condaless/lib/python3.8/site-packages/transformers/generation_beam_search.py:196: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "232\n",
      "232\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "min_length = 200\n",
    "max_length = 256\n",
    "num_beams = 12\n",
    "num_beam_groups = 12\n",
    "num_return_sequences = 4\n",
    "\n",
    "method = \"gbs_generate\"\n",
    "\n",
    "if method == \"beam_search\":\n",
    "    predictions_tok = model.generate(\n",
    "        **inputs, \n",
    "        repetition_penalty=3., \n",
    "        min_length=min_length, \n",
    "        num_beams=num_beams,\n",
    "        max_length=max_length,\n",
    "        temperature=2.0,\n",
    "        do_sample=True,\n",
    "        top_k=num_beams,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "elif method == \"gbs_generate\":\n",
    "    predictions_tok = model.generate(\n",
    "        **inputs, \n",
    "        repetition_penalty=3., \n",
    "        diversity_penalty=1000.,\n",
    "        min_length=min_length, \n",
    "        num_beams=num_beams,\n",
    "        max_length=max_length,\n",
    "        num_beam_groups=num_beam_groups,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "elif method == \"group_beam_search\":\n",
    "    scorer = transformers.BeamSearchScorer(\n",
    "        batch_size=1,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        length_penalty=1.0,\n",
    "        num_beam_hyps_to_keep=num_return_sequences,\n",
    "        num_beam_groups=num_beam_groups,\n",
    "    )\n",
    "\n",
    "    prediction_tok = model.group_beam_search(\n",
    "        **inputs, \n",
    "        repetition_penalty=2., \n",
    "        min_length=max_length, \n",
    "        diversity_penalty=0.75, \n",
    "        beam_scorer=scorer,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "for prediction_tok in predictions_tok:\n",
    "    print(len(prediction_tok))\n",
    "\n",
    "predictions = tokenizer.batch_decode(\n",
    "    predictions_tok, truncate=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(predictions) = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Attempt #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1878671576393452011</span>\n",
       "The heterogeneity of breast cancer has been well known for many years. It is now apparent \n",
       "that there are distinct genetic subtypes of breast cancer with very similar appearance at \n",
       "early stages and different mechanisms of carcinogenesis. This review summarizes the current \n",
       "knowledge on molecular features of breast cancer, their relevance to clinicopathological \n",
       "aspects and how these may be integrated into therapeutic strategies. The differences in the \n",
       "biology of breast cancer between epithelial and mesenchymal cells have been well documented. \n",
       "However, the complexity of cell biology makes it difficult to decipher the role of certain \n",
       "molecules in breast cancer. Recent studies have highlighted the importance of extracellular \n",
       "matrix <span style=\"font-weight: bold\">(</span> ecm<span style=\"font-weight: bold\">)</span>-responsive tumour-associated proteins. They have also emphasized the need for \n",
       "biomarkers that reflect tissue dysfunction. Immunohistochemical staining for a marker or \n",
       "combination of markers can identify those patients who are likely to benefit from targeted \n",
       "therapies. Analysis of genomic alterations provides information on the mechanism of action by\n",
       "which drugs affect disease progression. Understanding the role of specific molecules in \n",
       "breast cancer will lead to new therapeutics.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAttempt #\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1;36m-1878671576393452011\u001b[0m\n",
       "The heterogeneity of breast cancer has been well known for many years. It is now apparent \n",
       "that there are distinct genetic subtypes of breast cancer with very similar appearance at \n",
       "early stages and different mechanisms of carcinogenesis. This review summarizes the current \n",
       "knowledge on molecular features of breast cancer, their relevance to clinicopathological \n",
       "aspects and how these may be integrated into therapeutic strategies. The differences in the \n",
       "biology of breast cancer between epithelial and mesenchymal cells have been well documented. \n",
       "However, the complexity of cell biology makes it difficult to decipher the role of certain \n",
       "molecules in breast cancer. Recent studies have highlighted the importance of extracellular \n",
       "matrix \u001b[1m(\u001b[0m ecm\u001b[1m)\u001b[0m-responsive tumour-associated proteins. They have also emphasized the need for \n",
       "biomarkers that reflect tissue dysfunction. Immunohistochemical staining for a marker or \n",
       "combination of markers can identify those patients who are likely to benefit from targeted \n",
       "therapies. Analysis of genomic alterations provides information on the mechanism of action by\n",
       "which drugs affect disease progression. Understanding the role of specific molecules in \n",
       "breast cancer will lead to new therapeutics.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Attempt #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8308138390663326515</span>\n",
       "Molecular characterization of breast cancer has advanced significantly over recent decades \n",
       "with the discovery of many molecules and their interaction in this disease. These molecules \n",
       "are either mutated or have functions associated with tumour biology. The understanding of how\n",
       "a mutation affects a particular cell type has also increased with the discovery of new \n",
       "signalling pathways within that cell type. While some of these mechanisms can be directly \n",
       "linked to pathogenesis, others are indirectly determined by the cells themselves. It is now \n",
       "well accepted that there is a great deal of heterogeneity within the genetic alterations of \n",
       "breast cancer which must be considered when making clinical decisions. This review discusses \n",
       "the impact of emerging molecular technologies on the management of breast cancer. It is our \n",
       "hope that this article will serve as an initial small step towards achieving more accurate \n",
       "diagnosis and improved clinical management of patients with breast cancer through better \n",
       "understanding of mutations in genes and their relationship to phenotype. At the end of the \n",
       "review, we will discuss the next steps required to further advance the field, including the \n",
       "development of prognostic tools.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAttempt #\u001b[0m\u001b[1;36m1\u001b[0m: \u001b[1;36m8308138390663326515\u001b[0m\n",
       "Molecular characterization of breast cancer has advanced significantly over recent decades \n",
       "with the discovery of many molecules and their interaction in this disease. These molecules \n",
       "are either mutated or have functions associated with tumour biology. The understanding of how\n",
       "a mutation affects a particular cell type has also increased with the discovery of new \n",
       "signalling pathways within that cell type. While some of these mechanisms can be directly \n",
       "linked to pathogenesis, others are indirectly determined by the cells themselves. It is now \n",
       "well accepted that there is a great deal of heterogeneity within the genetic alterations of \n",
       "breast cancer which must be considered when making clinical decisions. This review discusses \n",
       "the impact of emerging molecular technologies on the management of breast cancer. It is our \n",
       "hope that this article will serve as an initial small step towards achieving more accurate \n",
       "diagnosis and improved clinical management of patients with breast cancer through better \n",
       "understanding of mutations in genes and their relationship to phenotype. At the end of the \n",
       "review, we will discuss the next steps required to further advance the field, including the \n",
       "development of prognostic tools.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Attempt #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7241039060724225035</span>\n",
       "Although advanced breast cancer is one of the most common causes for death in women, it has \n",
       "been difficult to achieve long-term remission with current standard of care because of \n",
       "complex underlying molecular genetic and environmental factors that determine disease \n",
       "activity. This review summarizes the progress made in identifying specific genetic \n",
       "alterations that contribute to breast cancer development and progression and provide an \n",
       "update on the current approaches being used to control tumour growth by targeting known \n",
       "pathways. These approaches include gene expression profiling using a panel of over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> genes,\n",
       "followed by analysis of mutations at least three times in a cohort of over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> patients \n",
       "before being approved by the us food and drug administration <span style=\"font-weight: bold\">(</span> fda <span style=\"font-weight: bold\">)</span> for use in clinical \n",
       "practice. There are also presented other studies showing how targeted therapies can be used \n",
       "to identify novel molecular targets, which will result in more effective management of \n",
       "patients with advanced breast cancer. Recent findings have also demonstrated that certain \n",
       "genetic alterations may not always correlate with aggressive phenotypes and that treatment \n",
       "response may differ according whether the patient's tumor is deregulated or hyperactivated \n",
       "based on the degree of alteration.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAttempt #\u001b[0m\u001b[1;36m2\u001b[0m: \u001b[1;36m-7241039060724225035\u001b[0m\n",
       "Although advanced breast cancer is one of the most common causes for death in women, it has \n",
       "been difficult to achieve long-term remission with current standard of care because of \n",
       "complex underlying molecular genetic and environmental factors that determine disease \n",
       "activity. This review summarizes the progress made in identifying specific genetic \n",
       "alterations that contribute to breast cancer development and progression and provide an \n",
       "update on the current approaches being used to control tumour growth by targeting known \n",
       "pathways. These approaches include gene expression profiling using a panel of over \u001b[1;36m200\u001b[0m genes,\n",
       "followed by analysis of mutations at least three times in a cohort of over \u001b[1;36m500\u001b[0m patients \n",
       "before being approved by the us food and drug administration \u001b[1m(\u001b[0m fda \u001b[1m)\u001b[0m for use in clinical \n",
       "practice. There are also presented other studies showing how targeted therapies can be used \n",
       "to identify novel molecular targets, which will result in more effective management of \n",
       "patients with advanced breast cancer. Recent findings have also demonstrated that certain \n",
       "genetic alterations may not always correlate with aggressive phenotypes and that treatment \n",
       "response may differ according whether the patient's tumor is deregulated or hyperactivated \n",
       "based on the degree of alteration.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Attempt #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4804912357575501047</span>\n",
       "Molecular characterization of breast cancer has advanced significantly over recent decades \n",
       "with the discovery of many molecules and their interaction in this disease. These molecules \n",
       "are either mutated or have functions associated with tumour biology. The understanding of how\n",
       "a mutation affects a particular cell type has also increased with the discovery of new \n",
       "signalling pathways within that cell type. While some of these mechanisms can be directly \n",
       "linked to pathogenesis, others are indirectly determined by the cells themselves. It is now \n",
       "well accepted that there is a great deal of heterogeneity within the genetic alterations of \n",
       "breast cancer which must be considered when making clinical decisions. This review discusses \n",
       "the impact of emerging molecular technologies on the management of breast cancer. It is our \n",
       "hope that this article will serve as an initial small step towards achieving more accurate \n",
       "diagnosis and improved clinical management of patients with breast cancer through better \n",
       "understanding of mutations in genes and their relationship to phenotype. At the end of the \n",
       "review, we will discuss the next steps required to further advance the field, including the \n",
       "development of prognostic tools. Both genetic and epigenetic techniques for breast cancer \n",
       "detection will be reviewed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAttempt #\u001b[0m\u001b[1;36m3\u001b[0m: \u001b[1;36m4804912357575501047\u001b[0m\n",
       "Molecular characterization of breast cancer has advanced significantly over recent decades \n",
       "with the discovery of many molecules and their interaction in this disease. These molecules \n",
       "are either mutated or have functions associated with tumour biology. The understanding of how\n",
       "a mutation affects a particular cell type has also increased with the discovery of new \n",
       "signalling pathways within that cell type. While some of these mechanisms can be directly \n",
       "linked to pathogenesis, others are indirectly determined by the cells themselves. It is now \n",
       "well accepted that there is a great deal of heterogeneity within the genetic alterations of \n",
       "breast cancer which must be considered when making clinical decisions. This review discusses \n",
       "the impact of emerging molecular technologies on the management of breast cancer. It is our \n",
       "hope that this article will serve as an initial small step towards achieving more accurate \n",
       "diagnosis and improved clinical management of patients with breast cancer through better \n",
       "understanding of mutations in genes and their relationship to phenotype. At the end of the \n",
       "review, we will discuss the next steps required to further advance the field, including the \n",
       "development of prognostic tools. Both genetic and epigenetic techniques for breast cancer \n",
       "detection will be reviewed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"{len(predictions) = }\")\n",
    "for i, prediction in enumerate(predictions):\n",
    "    one = prediction.replace(\"abstract\", \"[bold]Abstract:[/]\\n\"\n",
    "                    ).replace(\"<n>\", \"\"\n",
    "                    ).replace(\"<s>\", \"\"\n",
    "                    ).replace(\"<pad>\", \"\"\n",
    "                    ).replace(\"</s>\", \"\"\n",
    "                    ).replace(\" - \", \"-\")\n",
    "\n",
    "    two = [x.strip().capitalize() for x in one.split(\".\") if x]\n",
    "    three = \". \".join(two) + \".\"\n",
    "\n",
    "    rich.print(f\"[bold]Attempt #{i}[/]: \\n{three}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method generate in module transformers.generation_utils:\n",
      "\n",
      "generate(input_ids: Union[torch.LongTensor, NoneType] = None, max_length: Union[int, NoneType] = None, min_length: Union[int, NoneType] = None, do_sample: Union[bool, NoneType] = None, early_stopping: Union[bool, NoneType] = None, num_beams: Union[int, NoneType] = None, temperature: Union[float, NoneType] = None, top_k: Union[int, NoneType] = None, top_p: Union[float, NoneType] = None, repetition_penalty: Union[float, NoneType] = None, bad_words_ids: Union[Iterable[int], NoneType] = None, bos_token_id: Union[int, NoneType] = None, pad_token_id: Union[int, NoneType] = None, eos_token_id: Union[int, NoneType] = None, length_penalty: Union[float, NoneType] = None, no_repeat_ngram_size: Union[int, NoneType] = None, encoder_no_repeat_ngram_size: Union[int, NoneType] = None, num_return_sequences: Union[int, NoneType] = None, max_time: Union[float, NoneType] = None, max_new_tokens: Union[int, NoneType] = None, decoder_start_token_id: Union[int, NoneType] = None, use_cache: Union[bool, NoneType] = None, num_beam_groups: Union[int, NoneType] = None, diversity_penalty: Union[float, NoneType] = None, prefix_allowed_tokens_fn: Union[Callable[[int, torch.Tensor], List[int]], NoneType] = None, output_attentions: Union[bool, NoneType] = None, output_hidden_states: Union[bool, NoneType] = None, output_scores: Union[bool, NoneType] = None, return_dict_in_generate: Union[bool, NoneType] = None, forced_bos_token_id: Union[int, NoneType] = None, forced_eos_token_id: Union[int, NoneType] = None, remove_invalid_values: Union[bool, NoneType] = None, synced_gpus: Union[bool, NoneType] = None, **model_kwargs) -> Union[transformers.generation_utils.GreedySearchEncoderDecoderOutput, transformers.generation_utils.GreedySearchDecoderOnlyOutput, transformers.generation_utils.SampleEncoderDecoderOutput, transformers.generation_utils.SampleDecoderOnlyOutput, transformers.generation_utils.BeamSearchEncoderDecoderOutput, transformers.generation_utils.BeamSearchDecoderOnlyOutput, transformers.generation_utils.BeamSampleEncoderDecoderOutput, transformers.generation_utils.BeamSampleDecoderOnlyOutput, torch.LongTensor] method of transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration instance\n",
      "    Generates sequences for models with a language modeling head. The method currently supports greedy decoding,\n",
      "    multinomial sampling, beam-search decoding, and beam-search multinomial sampling.\n",
      "    \n",
      "    Apart from :obj:`input_ids` and :obj:`attention_mask`, all the arguments below will default to the value of the\n",
      "    attribute of the same name inside the :class:`~transformers.PretrainedConfig` of the model. The default values\n",
      "    indicated are the default values of those config.\n",
      "    \n",
      "    Most of these parameters are explained in more detail in `this blog post\n",
      "    <https://huggingface.co/blog/how-to-generate>`__.\n",
      "    \n",
      "    Parameters:\n",
      "    \n",
      "        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            The sequence used as a prompt for the generation. If :obj:`None` the method initializes it with\n",
      "            :obj:`bos_token_id` and a batch size of 1.\n",
      "        max_length (:obj:`int`, `optional`, defaults to :obj:`model.config.max_length`):\n",
      "            The maximum length of the sequence to be generated.\n",
      "        max_new_tokens (:obj:`int`, `optional`, defaults to None):\n",
      "            The maximum numbers of tokens to generate, ignore the current number of tokens. Use either\n",
      "            :obj:`max_new_tokens` or :obj:`max_length` but not both, they serve the same purpose.\n",
      "        min_length (:obj:`int`, `optional`, defaults to 10):\n",
      "            The minimum length of the sequence to be generated.\n",
      "        do_sample (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
      "            Whether or not to use sampling ; use greedy decoding otherwise.\n",
      "        early_stopping (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
      "            Whether to stop the beam search when at least ``num_beams`` sentences are finished per batch or not.\n",
      "        num_beams (:obj:`int`, `optional`, defaults to 1):\n",
      "            Number of beams for beam search. 1 means no beam search.\n",
      "        temperature (:obj:`float`, `optional`, defaults to 1.0):\n",
      "            The value used to module the next token probabilities.\n",
      "        top_k (:obj:`int`, `optional`, defaults to 50):\n",
      "            The number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
      "        top_p (:obj:`float`, `optional`, defaults to 1.0):\n",
      "            If set to float < 1, only the most probable tokens with probabilities that add up to :obj:`top_p` or\n",
      "            higher are kept for generation.\n",
      "        repetition_penalty (:obj:`float`, `optional`, defaults to 1.0):\n",
      "            The parameter for repetition penalty. 1.0 means no penalty. See `this paper\n",
      "            <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details.\n",
      "        pad_token_id (:obj:`int`, `optional`):\n",
      "            The id of the `padding` token.\n",
      "        bos_token_id (:obj:`int`, `optional`):\n",
      "            The id of the `beginning-of-sequence` token.\n",
      "        eos_token_id (:obj:`int`, `optional`):\n",
      "            The id of the `end-of-sequence` token.\n",
      "        length_penalty (:obj:`float`, `optional`, defaults to 1.0):\n",
      "            Exponential penalty to the length. 1.0 means no penalty. Set to values < 1.0 in order to encourage the\n",
      "            model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer\n",
      "            sequences.\n",
      "        no_repeat_ngram_size (:obj:`int`, `optional`, defaults to 0):\n",
      "            If set to int > 0, all ngrams of that size can only occur once.\n",
      "        encoder_no_repeat_ngram_size (:obj:`int`, `optional`, defaults to 0):\n",
      "            If set to int > 0, all ngrams of that size that occur in the ``encoder_input_ids`` cannot occur in the\n",
      "            ``decoder_input_ids``.\n",
      "        bad_words_ids(:obj:`List[List[int]]`, `optional`):\n",
      "            List of token ids that are not allowed to be generated. In order to get the tokens of the words that\n",
      "            should not appear in the generated text, use :obj:`tokenizer(bad_word,\n",
      "            add_prefix_space=True).input_ids`.\n",
      "        num_return_sequences(:obj:`int`, `optional`, defaults to 1):\n",
      "            The number of independently computed returned sequences for each element in the batch.\n",
      "        max_time(:obj:`float`, `optional`, defaults to None):\n",
      "            The maximum amount of time you allow the computation to run for in seconds. generation will still\n",
      "            finish the current pass after allocated time has been passed.\n",
      "        attention_mask (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
      "            Mask to avoid performing attention on padding token indices. Mask values are in ``[0, 1]``, 1 for\n",
      "            tokens that are not masked, and 0 for masked tokens. If not provided, will default to a tensor the same\n",
      "            shape as :obj:`input_ids` that masks the pad token. `What are attention masks?\n",
      "            <../glossary.html#attention-mask>`__\n",
      "        decoder_start_token_id (:obj:`int`, `optional`):\n",
      "            If an encoder-decoder model starts decoding with a different token than `bos`, the id of that token.\n",
      "        use_cache: (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
      "            Whether or not the model should use the past last key/values attentions (if applicable to the model) to\n",
      "            speed up decoding.\n",
      "        num_beam_groups (:obj:`int`, `optional`, defaults to 1):\n",
      "            Number of groups to divide :obj:`num_beams` into in order to ensure diversity among different groups of\n",
      "            beams. `this paper <https://arxiv.org/pdf/1610.02424.pdf>`__ for more details.\n",
      "        diversity_penalty (:obj:`float`, `optional`, defaults to 0.0):\n",
      "            This value is subtracted from a beam's score if it generates a token same as any beam from other group\n",
      "            at a particular time. Note that :obj:`diversity_penalty` is only effective if ``group beam search`` is\n",
      "            enabled.\n",
      "        prefix_allowed_tokens_fn: (:obj:`Callable[[int, torch.Tensor], List[int]]`, `optional`):\n",
      "            If provided, this function constraints the beam search to allowed tokens only at each step. If not\n",
      "            provided no constraint is applied. This function takes 2 arguments: the batch ID :obj:`batch_id` and\n",
      "            :obj:`input_ids`. It has to return a list with the allowed tokens for the next generation step\n",
      "            conditioned on the batch ID :obj:`batch_id` and the previously generated tokens :obj:`inputs_ids`. This\n",
      "            argument is useful for constrained generation conditioned on the prefix, as described in\n",
      "            `Autoregressive Entity Retrieval <https://arxiv.org/abs/2010.00904>`__.\n",
      "        output_attentions (:obj:`bool`, `optional`, defaults to `False`):\n",
      "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n",
      "            returned tensors for more details.\n",
      "        output_hidden_states (:obj:`bool`, `optional`, defaults to `False`):\n",
      "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors\n",
      "            for more details.\n",
      "        output_scores (:obj:`bool`, `optional`, defaults to `False`):\n",
      "            Whether or not to return the prediction scores. See ``scores`` under returned tensors for more details.\n",
      "        return_dict_in_generate (:obj:`bool`, `optional`, defaults to `False`):\n",
      "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
      "        forced_bos_token_id (:obj:`int`, `optional`):\n",
      "            The id of the token to force as the first generated token after the :obj:`decoder_start_token_id`.\n",
      "            Useful for multilingual models like :doc:`mBART <../model_doc/mbart>` where the first generated token\n",
      "            needs to be the target language token.\n",
      "        forced_eos_token_id (:obj:`int`, `optional`):\n",
      "            The id of the token to force as the last generated token when :obj:`max_length` is reached.\n",
      "        remove_invalid_values (:obj:`bool`, `optional`):\n",
      "            Whether to remove possible `nan` and `inf` outputs of the model to prevent the generation method to\n",
      "            crash. Note that using ``remove_invalid_values`` can slow down generation.\n",
      "        synced_gpus (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
      "            Whether to continue running the while loop until max_length (needed for ZeRO stage 3)\n",
      "    \n",
      "        model_kwargs:\n",
      "            Additional model specific kwargs will be forwarded to the :obj:`forward` function of the model. If the\n",
      "            model is an encoder-decoder model, encoder specific kwargs should not be prefixed and decoder specific\n",
      "            kwargs should be prefixed with `decoder_`.\n",
      "    \n",
      "    Return:\n",
      "        :class:`~transformers.file_utils.ModelOutput` or :obj:`torch.LongTensor`: A\n",
      "        :class:`~transformers.file_utils.ModelOutput` (if ``return_dict_in_generate=True`` or when\n",
      "        ``config.return_dict_in_generate=True``) or a :obj:`torch.FloatTensor`.\n",
      "    \n",
      "            If the model is `not` an encoder-decoder model (``model.config.is_encoder_decoder=False``), the\n",
      "            possible :class:`~transformers.file_utils.ModelOutput` types are:\n",
      "    \n",
      "                - :class:`~transformers.generation_utils.GreedySearchDecoderOnlyOutput`,\n",
      "                - :class:`~transformers.generation_utils.SampleDecoderOnlyOutput`,\n",
      "                - :class:`~transformers.generation_utils.BeamSearchDecoderOnlyOutput`,\n",
      "                - :class:`~transformers.generation_utils.BeamSampleDecoderOnlyOutput`\n",
      "    \n",
      "            If the model is an encoder-decoder model (``model.config.is_encoder_decoder=True``), the possible\n",
      "            :class:`~transformers.file_utils.ModelOutput` types are:\n",
      "    \n",
      "                - :class:`~transformers.generation_utils.GreedySearchEncoderDecoderOutput`,\n",
      "                - :class:`~transformers.generation_utils.SampleEncoderDecoderOutput`,\n",
      "                - :class:`~transformers.generation_utils.BeamSearchEncoderDecoderOutput`,\n",
      "                - :class:`~transformers.generation_utils.BeamSampleEncoderDecoderOutput`\n",
      "    \n",
      "    Examples::\n",
      "        >>> from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
      "    \n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
      "        >>> model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
      "        >>> # do greedy decoding without providing a prompt\n",
      "        >>> outputs = model.generate(max_length=40)\n",
      "        >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
      "    \n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
      "        >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
      "        >>> document = (\n",
      "        ... \"at least two people were killed in a suspected bomb attack on a passenger bus \"\n",
      "        ... \"in the strife-torn southern philippines on monday , the military said.\"\n",
      "        ... )\n",
      "        >>> # encode input context\n",
      "        >>> input_ids = tokenizer(document, return_tensors=\"pt\").input_ids\n",
      "        >>> # generate 3 independent sequences using beam search decoding (5 beams)\n",
      "        >>> # with T5 encoder-decoder model conditioned on short news article.\n",
      "        >>> outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3)\n",
      "        >>> print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
      "    \n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
      "        >>> model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
      "        >>> input_context = \"The dog\"\n",
      "        >>> # encode input context\n",
      "        >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
      "        >>> # generate 3 candidates using sampling\n",
      "        >>> outputs = model.generate(input_ids=input_ids, max_length=20, num_return_sequences=3, do_sample=True)\n",
      "        >>> print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
      "    \n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"ctrl\")\n",
      "        >>> model = AutoModelForCausalLM.from_pretrained(\"ctrl\")\n",
      "        >>> # \"Legal\" is one of the control codes for ctrl\n",
      "        >>> input_context = \"Legal My neighbor is\"\n",
      "        >>> # encode input context\n",
      "        >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
      "        >>> outputs = model.generate(input_ids=input_ids, max_length=20, repetition_penalty=1.2)\n",
      "        >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
      "    \n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
      "        >>> model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
      "        >>> input_context = \"My cute dog\"\n",
      "        >>> # get tokens of words that should not be generated\n",
      "        >>> bad_words_ids = [tokenizer(bad_word, add_prefix_space=True).input_ids for bad_word in [\"idiot\", \"stupid\", \"shut up\"]]\n",
      "        >>> # encode input context\n",
      "        >>> input_ids = tokenizer(input_context, return_tensors=\"pt\").input_ids\n",
      "        >>> # generate sequences without allowing bad_words to be generated\n",
      "        >>> outputs = model.generate(input_ids=input_ids, max_length=20, do_sample=True, bad_words_ids=bad_words_ids)\n",
      "        >>> print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4373dfae08f86e1cbb30276a64388ceb0cca01fb3413c04c67d6728de3721b03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
